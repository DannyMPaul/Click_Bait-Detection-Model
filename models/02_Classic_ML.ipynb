{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02 — Classic ML: TF-IDF + Naive Bayes + SVM\n",
                "\n",
                "**Project:** Clickbait Headline Detector  \n",
                "Baseline model using traditional NLP features. Fast, interpretable, and a solid reference point.\n",
                "\n",
                "> Requires `data/cleaned.csv` — run `01_EDA.ipynb` first."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import re\n",
                "import os\n",
                "import warnings\n",
                "import joblib\n",
                "\n",
                "import nltk\n",
                "nltk.download('stopwords', quiet=True)\n",
                "from nltk.corpus import stopwords\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.naive_bayes import MultinomialNB\n",
                "from sklearn.svm import LinearSVC\n",
                "from sklearn.calibration import CalibratedClassifierCV   # gives SVM proper probabilities\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "\n",
                "STOP_WORDS = set(stopwords.words('english'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CLEANED_PATH = 'data/cleaned.csv'\n",
                "MODELS_DIR   = 'models'\n",
                "RANDOM_STATE = 42\n",
                "TEST_SIZE    = 0.2\n",
                "\n",
                "os.makedirs(MODELS_DIR, exist_ok=True)\n",
                "\n",
                "assert os.path.exists(CLEANED_PATH), (\n",
                "    f'File not found: {CLEANED_PATH!r}. Run 01_EDA.ipynb first.'\n",
                ")\n",
                "print('Config OK.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load & Preprocess"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(CLEANED_PATH)\n",
                "print(f'Loaded {len(df)} rows — class balance: {df[\"label\"].value_counts().to_dict()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_text(text):\n",
                "    \"\"\"Lowercase, strip non-alpha chars, remove stopwords.\"\"\"\n",
                "    text = re.sub('[^a-z ]', '', str(text).lower())\n",
                "    return ' '.join(w for w in text.split() if w not in STOP_WORDS and len(w) > 1)\n",
                "\n",
                "\n",
                "df['clean'] = df['headline'].apply(clean_text)\n",
                "\n",
                "print(df[['headline', 'clean']].head(3).to_string())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train / Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    df['clean'], df['label'],\n",
                "    test_size=TEST_SIZE,\n",
                "    random_state=RANDOM_STATE,\n",
                "    stratify=df['label']\n",
                ")\n",
                "print(f'Train: {len(X_train)} samples  |  Test: {len(X_test)} samples')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## TF-IDF Vectorisation\n",
                "Using unigrams + bigrams so the model can pick up two-word signals like *\"you won't\"* or *\"find out\"*."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=50_000)\n",
                "\n",
                "X_train_vec = tfidf.fit_transform(X_train)   # fit on train only — avoid data leakage\n",
                "X_test_vec  = tfidf.transform(X_test)\n",
                "\n",
                "print(f'Vocab size: {len(tfidf.vocabulary_):,}')\n",
                "print(f'Matrix shape (train): {X_train_vec.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model A — Naive Bayes\n",
                "MultinomialNB has `predict_proba()` built-in — confidence scores work out of the box."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nb = MultinomialNB(alpha=0.1)\n",
                "nb.fit(X_train_vec, y_train)\n",
                "\n",
                "nb_preds = nb.predict(X_test_vec)\n",
                "nb_acc   = accuracy_score(y_test, nb_preds)\n",
                "\n",
                "print(f'Naive Bayes Accuracy: {nb_acc:.4f}\\n')\n",
                "print(classification_report(y_test, nb_preds, target_names=['Real', 'Clickbait']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model B — SVM (LinearSVC + Calibration)\n",
                "LinearSVC doesn't produce probabilities natively.  \n",
                "`CalibratedClassifierCV` wraps it with Platt scaling so we get proper `predict_proba()` output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "base_svm = LinearSVC(C=1.0, max_iter=2000, random_state=RANDOM_STATE)\n",
                "\n",
                "# cv=5 means the calibration uses 5-fold cross-val — more reliable probability estimates\n",
                "svm = CalibratedClassifierCV(base_svm, cv=5)\n",
                "svm.fit(X_train_vec, y_train)\n",
                "\n",
                "svm_preds = svm.predict(X_test_vec)\n",
                "svm_acc   = accuracy_score(y_test, svm_preds)\n",
                "\n",
                "print(f'SVM Accuracy: {svm_acc:.4f}\\n')\n",
                "print(classification_report(y_test, svm_preds, target_names=['Real', 'Clickbait']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Comparison — Confusion Matrices"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "for ax, preds, name, acc in zip(\n",
                "    axes,\n",
                "    [nb_preds, svm_preds],\n",
                "    ['Naive Bayes', 'SVM (Calibrated)'],\n",
                "    [nb_acc, svm_acc]\n",
                "):\n",
                "    cm = confusion_matrix(y_test, preds)\n",
                "    sns.heatmap(\n",
                "        cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
                "        xticklabels=['Real', 'Clickbait'],\n",
                "        yticklabels=['Real', 'Clickbait']\n",
                "    )\n",
                "    ax.set_title(f'{name}\\nAccuracy: {acc:.4f}')\n",
                "    ax.set_xlabel('Predicted')\n",
                "    ax.set_ylabel('Actual')\n",
                "\n",
                "plt.suptitle('Classic ML — Confusion Matrices', fontsize=14, y=1.02)\n",
                "plt.tight_layout()\n",
                "plt.savefig('models/classic_confusion_matrices.png', dpi=120, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "results = pd.DataFrame({\n",
                "    'Model':    ['Naive Bayes', 'SVM (Calibrated)'],\n",
                "    'Accuracy': [round(nb_acc, 4), round(svm_acc, 4)]\n",
                "})\n",
                "print('\\n--- Model Comparison ---')\n",
                "print(results.to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save Best Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "best_model = svm if svm_acc >= nb_acc else nb\n",
                "best_name  = 'SVM' if svm_acc >= nb_acc else 'NaiveBayes'\n",
                "\n",
                "joblib.dump(tfidf,      f'{MODELS_DIR}/tfidf_vectorizer.pkl')\n",
                "joblib.dump(best_model, f'{MODELS_DIR}/best_classic_model.pkl')\n",
                "\n",
                "print(f'Saved best model ({best_name}) and TF-IDF vectorizer to {MODELS_DIR!r}/')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Try Your Own Headline\n",
                "Change the string below and run the cell — it will tell you the prediction and how confident the model is."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Change this to any headline you want to test ---\n",
                "my_headline = 'You will not believe what this celebrity did next!'\n",
                "\n",
                "\n",
                "def predict_classic(headline, model, vectorizer):\n",
                "    \"\"\"Clean, vectorise, and predict a single headline. Returns label + confidence.\"\"\"\n",
                "    cleaned = clean_text(headline)\n",
                "    vec     = vectorizer.transform([cleaned])\n",
                "    label   = model.predict(vec)[0]\n",
                "    proba   = model.predict_proba(vec)[0]  # [P(real), P(clickbait)]\n",
                "    confidence = proba[label] * 100\n",
                "    return {\n",
                "        'headline'  : headline,\n",
                "        'prediction': 'Clickbait' if label == 1 else 'Real News',\n",
                "        'confidence': f'{confidence:.1f}%'\n",
                "    }\n",
                "\n",
                "\n",
                "result = predict_classic(my_headline, best_model, tfidf)\n",
                "\n",
                "print(f'Headline   : {result[\"headline\"]}')\n",
                "print(f'Prediction : {result[\"prediction\"]}')\n",
                "print(f'Confidence : {result[\"confidence\"]}')"
            ]
        }
    ]
}