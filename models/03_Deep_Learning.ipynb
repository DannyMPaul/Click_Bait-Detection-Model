{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 03 — Deep Learning: Bidirectional LSTM\n",
                "\n",
                "**Project:** Clickbait Headline Detector  \n",
                "A neural network that reads headlines as sequences, capturing word order that TF-IDF ignores.\n",
                "\n",
                "> Requires `data/cleaned.csv` — run `01_EDA.ipynb` first."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import re\n",
                "import os\n",
                "import warnings\n",
                "\n",
                "import nltk\n",
                "nltk.download('stopwords', quiet=True)\n",
                "from nltk.corpus import stopwords\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
                "from tensorflow.keras.preprocessing.text import Tokenizer\n",
                "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)\n",
                "\n",
                "STOP_WORDS = set(stopwords.words('english'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Config\n",
                "All tunable hyperparameters live here — tweak these before re-running the training cell."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CLEANED_PATH = 'data/cleaned.csv'\n",
                "MODELS_DIR   = 'models'\n",
                "\n",
                "# Tokenisation\n",
                "VOCAB_SIZE = 20_000   # keep the top N most frequent words\n",
                "MAX_LEN    = 30       # headlines rarely exceed 30 words; pad/truncate to this\n",
                "\n",
                "# Model\n",
                "EMBED_DIM  = 64       # embedding vector size per word\n",
                "LSTM_UNITS = 64       # hidden units per LSTM direction\n",
                "\n",
                "# Training\n",
                "EPOCHS       = 20     # EarlyStopping will cut this short if needed\n",
                "BATCH_SIZE   = 64\n",
                "RANDOM_STATE = 42\n",
                "TEST_SIZE    = 0.2\n",
                "\n",
                "os.makedirs(MODELS_DIR, exist_ok=True)\n",
                "\n",
                "assert os.path.exists(CLEANED_PATH), (\n",
                "    f'File not found: {CLEANED_PATH!r}. Run 01_EDA.ipynb first.'\n",
                ")\n",
                "print('Config OK.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load & Clean"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(CLEANED_PATH)\n",
                "print(f'Loaded {len(df)} rows.')\n",
                "\n",
                "\n",
                "def clean_text(text):\n",
                "    \"\"\"Lowercase, strip non-alpha chars, remove stopwords.\"\"\"\n",
                "    text = re.sub('[^a-z ]', '', str(text).lower())\n",
                "    return ' '.join(w for w in text.split() if w not in STOP_WORDS and len(w) > 1)\n",
                "\n",
                "\n",
                "df['clean'] = df['headline'].apply(clean_text)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Tokenise & Pad\n",
                "Convert words to integer indices, then pad all sequences to the same length so they batch cleanly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token='<OOV>')\n",
                "tokenizer.fit_on_texts(df['clean'])\n",
                "\n",
                "sequences = tokenizer.texts_to_sequences(df['clean'])\n",
                "padded    = pad_sequences(sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
                "labels    = df['label'].values\n",
                "\n",
                "actual_vocab = min(VOCAB_SIZE, len(tokenizer.word_index))\n",
                "print(f'Vocabulary size : {actual_vocab:,} unique tokens')\n",
                "print(f'Padded shape    : {padded.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train / Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    padded, labels,\n",
                "    test_size=TEST_SIZE,\n",
                "    random_state=RANDOM_STATE,\n",
                "    stratify=labels\n",
                ")\n",
                "print(f'Train: {len(X_train)} samples  |  Test: {len(X_test)} samples')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model Architecture\n",
                "`Embedding → Dropout → Bidirectional LSTM → Dropout → Dense → Sigmoid`  \n",
                "Bidirectional lets the LSTM read each headline left-to-right *and* right-to-left before deciding."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = Sequential([\n",
                "    Embedding(input_dim=VOCAB_SIZE, output_dim=EMBED_DIM, input_length=MAX_LEN),\n",
                "    Dropout(0.3),\n",
                "    Bidirectional(LSTM(LSTM_UNITS)),\n",
                "    Dropout(0.3),\n",
                "    Dense(32, activation='relu'),\n",
                "    Dense(1, activation='sigmoid')   # outputs a value 0‒1; threshold at 0.5 for label\n",
                "])\n",
                "\n",
                "model.compile(\n",
                "    optimizer='adam',\n",
                "    loss='binary_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train\n",
                "`EarlyStopping` halts training when validation loss stops improving.  \n",
                "`ReduceLROnPlateau` lowers the learning rate when progress stalls."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "callbacks = [\n",
                "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1),\n",
                "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
                "]\n",
                "\n",
                "history = model.fit(\n",
                "    X_train, y_train,\n",
                "    validation_split=0.1,\n",
                "    epochs=EPOCHS,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Curves\n",
                "Look for val curves diverging from train — a sign of overfitting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "axes[0].plot(history.history['accuracy'],     label='Train', color='steelblue')\n",
                "axes[0].plot(history.history['val_accuracy'], label='Val',   color='tomato', linestyle='--')\n",
                "axes[0].set_title('Accuracy per Epoch')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].set_ylabel('Accuracy')\n",
                "axes[0].legend()\n",
                "\n",
                "axes[1].plot(history.history['loss'],     label='Train', color='steelblue')\n",
                "axes[1].plot(history.history['val_loss'], label='Val',   color='tomato', linestyle='--')\n",
                "axes[1].set_title('Loss per Epoch')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].set_ylabel('Loss')\n",
                "axes[1].legend()\n",
                "\n",
                "plt.suptitle('LSTM Training History', fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.savefig('models/lstm_training_history.png', dpi=120, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Evaluate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
                "preds     = (model.predict(X_test, verbose=0) > 0.5).astype(int).flatten()\n",
                "\n",
                "print(f'Test Accuracy : {acc:.4f}')\n",
                "print(f'Test Loss     : {loss:.4f}\\n')\n",
                "print(classification_report(y_test, preds, target_names=['Real', 'Clickbait']))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cm = confusion_matrix(y_test, preds)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(6, 5))\n",
                "sns.heatmap(\n",
                "    cm, annot=True, fmt='d', cmap='Purples', ax=ax,\n",
                "    xticklabels=['Real', 'Clickbait'],\n",
                "    yticklabels=['Real', 'Clickbait']\n",
                ")\n",
                "ax.set_title(f'LSTM Confusion Matrix — Accuracy: {acc:.4f}')\n",
                "ax.set_xlabel('Predicted')\n",
                "ax.set_ylabel('Actual')\n",
                "plt.tight_layout()\n",
                "plt.savefig('models/lstm_confusion_matrix.png', dpi=120, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.save(f'{MODELS_DIR}/lstm_model.h5')\n",
                "print(f'Model saved to {MODELS_DIR!r}/lstm_model.h5')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Try Your Own Headline\n",
                "The sigmoid output is naturally a confidence score — values close to 1 mean the model is very sure it's clickbait, close to 0 means it's confident it's real news.  \n",
                "Change the string below and run the cell."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Change this to any headline you want to test ---\n",
                "my_headline = 'You will not believe what this celebrity did next!'\n",
                "\n",
                "\n",
                "def predict_lstm(headline, model, tokenizer, max_len):\n",
                "    \"\"\"\n",
                "    Clean, tokenise, and predict a single headline.\n",
                "    Returns the label and the raw sigmoid score as a confidence percentage.\n",
                "    \"\"\"\n",
                "    cleaned  = clean_text(headline)\n",
                "    seq      = tokenizer.texts_to_sequences([cleaned])\n",
                "    padded   = pad_sequences(seq, maxlen=max_len, padding='post', truncating='post')\n",
                "    score    = float(model.predict(padded, verbose=0)[0][0])   # raw sigmoid output\n",
                "\n",
                "    if score >= 0.5:\n",
                "        label      = 'Clickbait'\n",
                "        confidence = score              # high score → confident clickbait\n",
                "    else:\n",
                "        label      = 'Real News'\n",
                "        confidence = 1.0 - score       # low score → confident real news\n",
                "\n",
                "    return {\n",
                "        'headline'    : headline,\n",
                "        'prediction'  : label,\n",
                "        'confidence'  : f'{confidence * 100:.1f}%',\n",
                "        'raw_score'   : f'{score:.4f}  (0 = very real, 1 = very clickbait)'\n",
                "    }\n",
                "\n",
                "\n",
                "result = predict_lstm(my_headline, model, tokenizer, MAX_LEN)\n",
                "\n",
                "print(f'Headline    : {result[\"headline\"]}')\n",
                "print(f'Prediction  : {result[\"prediction\"]}')\n",
                "print(f'Confidence  : {result[\"confidence\"]}')\n",
                "print(f'Raw score   : {result[\"raw_score\"]}')"
            ]
        }
    ]
}